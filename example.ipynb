{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "example.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "e2NULMLN6eea",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "200aeb3e-331e-49ae-fc09-2eda630d43c4"
      },
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('universal_tagset')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('brown')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z1AYTSc7Fm_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "27b09b2f-7519-41a3-a251-06a73b32648e"
      },
      "source": [
        "!pip install resume-parser"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting resume-parser\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/c9/9141dd2b7520344b640b0e2eef7e892e9e2993768e74a4c596f8126ef8dd/resume_parser-0.4.tar.gz (4.9MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9MB 4.6MB/s \n",
            "\u001b[?25hCollecting docx2txt>=0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/7d/7d/60ee3f2b16d9bfdfa72e8599470a2c1a5b759cb113c6fe1006be28359327/docx2txt-0.8.tar.gz\n",
            "Collecting nltk>=3.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 36.9MB/s \n",
            "\u001b[?25hCollecting numpy>=1.19.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/9a/7d474ba0860a41f771c9523d8c4ea56b084840b5ca4092d96bdee8a3b684/numpy-1.19.1-cp36-cp36m-manylinux2010_x86_64.whl (14.5MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5MB 301kB/s \n",
            "\u001b[?25hCollecting pandas>=1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/c6/9ac4ae44c24c787a1738e5fb34dd987ada6533de5905a041aa6d5bea4553/pandas-1.1.1-cp36-cp36m-manylinux1_x86_64.whl (10.5MB)\n",
            "\u001b[K     |████████████████████████████████| 10.5MB 42.8MB/s \n",
            "\u001b[?25hCollecting pdfminer.six>=20200517\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/12/ab5ebafc4cb2b49847de7bfc26f2d152f42a4af136263152d070c61dfd7d/pdfminer.six-20200726-py3-none-any.whl (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 12.8MB/s \n",
            "\u001b[?25hCollecting pdfplumber>=0.5.23\n",
            "  Downloading https://files.pythonhosted.org/packages/2c/06/eb883f00ea3d78a2f860c593645498c39120f763d30b099cc98c4392b312/pdfplumber-0.5.23.tar.gz\n",
            "Collecting phonenumbers>=8.12.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/7a/bf7d31aee3bb295a49fc91854109615d368b99f9de53c959ed8c79b5532c/phonenumbers-8.12.9-py2.py3-none-any.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 30.9MB/s \n",
            "\u001b[?25hCollecting spacy>=2.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/b5/c7a92c7ce5d4b353b70b4b5b4385687206c8b230ddfe08746ab0fd310a3a/spacy-2.3.2-cp36-cp36m-manylinux1_x86_64.whl (9.9MB)\n",
            "\u001b[K     |████████████████████████████████| 10.0MB 28.2MB/s \n",
            "\u001b[?25hCollecting stemming>=1.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/eb/fd53fb51b83a4e3b8e98cfec2fa9e4b99401fce5177ec346e4a5c61df71e/stemming-1.0.1.tar.gz\n",
            "Collecting tika>=1.24\n",
            "  Downloading https://files.pythonhosted.org/packages/96/07/244fbb9c74c0de8a3745cc9f3f496077a29f6418c7cbd90d68fd799574cb/tika-1.24.tar.gz\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from nltk>=3.5->resume-parser) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from nltk>=3.5->resume-parser) (0.16.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from nltk>=3.5->resume-parser) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk>=3.5->resume-parser) (4.41.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.1.0->resume-parser) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.1.0->resume-parser) (2.8.1)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.6/dist-packages (from pdfminer.six>=20200517->resume-parser) (2.2.2)\n",
            "Requirement already satisfied: chardet; python_version > \"3.0\" in /usr/local/lib/python3.6/dist-packages (from pdfminer.six>=20200517->resume-parser) (3.0.4)\n",
            "Collecting cryptography\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/9c/647e559a6e8be493dc2a7a5d15d26cb501ca60ec299b356f23839a673a83/cryptography-3.1-cp35-abi3-manylinux2010_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 36.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow>=7.0.0 in /usr/local/lib/python3.6/dist-packages (from pdfplumber>=0.5.23->resume-parser) (7.0.0)\n",
            "Collecting Wand\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/e4/d00cdc270cad06a2dd2d3095ffe0f6541d69104db504c4e94de805e3c6e0/Wand-0.6.2-py2.py3-none-any.whl (130kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 45.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.3.2->resume-parser) (3.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.3.2->resume-parser) (2.0.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.3.2->resume-parser) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.3.2->resume-parser) (1.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.3.2->resume-parser) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.3.2->resume-parser) (1.1.3)\n",
            "Collecting thinc==7.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/ae/ef3ae5e93639c0ef8e3eb32e3c18341e511b3c515fcfc603f4b808087651/thinc-7.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 37.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.3.2->resume-parser) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.3.2->resume-parser) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.3.2->resume-parser) (0.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.3.2->resume-parser) (49.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1.0->resume-parser) (1.15.0)\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography->pdfminer.six>=20200517->resume-parser) (1.14.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.2->resume-parser) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.2->resume-parser) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.2->resume-parser) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.3.2->resume-parser) (1.7.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography->pdfminer.six>=20200517->resume-parser) (2.20)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.3.2->resume-parser) (3.1.0)\n",
            "Building wheels for collected packages: resume-parser, docx2txt, nltk, pdfplumber, stemming, tika\n",
            "  Building wheel for resume-parser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for resume-parser: filename=resume_parser-0.4-cp36-none-any.whl size=4896868 sha256=7b60ca521f4b7de7996e8e8ac10551fc03983dc142d8207c750415d7f0ba2bb1\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/8e/82/b4379d7f05a31dbf5ffa2112f4891986f6ad139bbf3fbcf328\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-cp36-none-any.whl size=3965 sha256=00bb44f8c2aab90cce0565b6e00520288bb109ff59f17764a410526e05a2b910\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/1f/26/a051209bbb77fc6bcfae2bb7e01fa0ff941b82292ab084d596\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.5-cp36-none-any.whl size=1434677 sha256=c6a3937dc1e74c6c9496d5abe9e595248fa8f7636779d26e095ec795a15eea21\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
            "  Building wheel for pdfplumber (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pdfplumber: filename=pdfplumber-0.5.23-cp36-none-any.whl size=29176 sha256=ec1b25b0e9e252c02574f9528ff49591963edf8446a46620808a8fb937293122\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/4d/ae/abb7b92fbed5d09a835c259f26d2a3223ea929a0ad6d322097\n",
            "  Building wheel for stemming (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stemming: filename=stemming-1.0.1-cp36-none-any.whl size=11140 sha256=a570d04b7233819a19db66469882a8687e2acc9d3c78951bd9938298e3c87954\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/05/2e/2ddeb64d4464b854b48323f9676528c17560da7d153db7b0e2\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-1.24-cp36-none-any.whl size=32884 sha256=5156fc63493eb14a6b433344ce007a8dda6a14aecc360df06ab55218690e98c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/9c/f5/0b1b738442fc2a2862bef95b908b374f8e80215550fb2a8975\n",
            "Successfully built resume-parser docx2txt nltk pdfplumber stemming tika\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.0.0; python_version >= \"3.0\", but you'll have pandas 1.1.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pdfplumber 0.5.23 has requirement pdfminer.six==20200517, but you'll have pdfminer-six 20200726 which is incompatible.\u001b[0m\n",
            "Installing collected packages: docx2txt, nltk, numpy, pandas, cryptography, pdfminer.six, Wand, pdfplumber, phonenumbers, thinc, spacy, stemming, tika, resume-parser\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "  Found existing installation: pandas 1.0.5\n",
            "    Uninstalling pandas-1.0.5:\n",
            "      Successfully uninstalled pandas-1.0.5\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed Wand-0.6.2 cryptography-3.1 docx2txt-0.8 nltk-3.5 numpy-1.19.1 pandas-1.1.1 pdfminer.six-20200726 pdfplumber-0.5.23 phonenumbers-8.12.9 resume-parser-0.4 spacy-2.3.2 stemming-1.0.1 thinc-7.4.1 tika-1.24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nltk",
                  "numpy",
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4uzK3uU7BXt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "4a5dafd8-f6b8-4965-c4c9-4e398858b038"
      },
      "source": [
        "!wget \"https://github.com/kbrajwani/resume_parser/raw/master/Kumar's%20Resume.pdf\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-08 04:18:28--  https://github.com/kbrajwani/resume_parser/raw/master/Kumar's%20Resume.pdf\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/kbrajwani/resume_parser/master/Kumar's%20Resume.pdf [following]\n",
            "--2020-09-08 04:18:28--  https://raw.githubusercontent.com/kbrajwani/resume_parser/master/Kumar's%20Resume.pdf\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 55603 (54K) [application/octet-stream]\n",
            "Saving to: ‘Kumar's Resume.pdf’\n",
            "\n",
            "Kumar's Resume.pdf  100%[===================>]  54.30K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-09-08 04:18:29 (3.40 MB/s) - ‘Kumar's Resume.pdf’ saved [55603/55603]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OC7mqfc6eeo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "f3519eed-e171-476d-f6ca-10421077c324"
      },
      "source": [
        "from resume_parser import resumeparse\n",
        "resumeparse.read_file(\"Kumar's Resume.pdf\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020 2019\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'degree': [],\n",
              " 'designition': ['learning engineer', 'python developer', 'content writer'],\n",
              " 'email': 'kumarrajwani1811@gmail.com',\n",
              " 'name': 'Kumar Rajwani',\n",
              " 'phone': '8141873476',\n",
              " 'skills': 'https machine learning classification nlp pdf computer vision artificial intelligence web security google',\n",
              " 'total_exp': 1,\n",
              " 'university': []}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    }
  ]
}